# üåç ESP32 Disaster Detection with TinyML

**Title:** Improved Accuracy in Edge-Based Disaster Detection: Revisiting Prior Models Using TinyML on ESP32  
**Authors:** Samik, Ankit Ghosh, and Dr. Jyoti Yadav  
**Affiliation:** Delhi Skill and Entrepreneurship University (DSEU), India  
**Contact:** samik.workofficial@gmail.com

---

## üìå Overview

This repository contains all resources related to our research work on deploying a **real-time calamity detection system using TinyML on ESP32**. The model detects disasters such as floods, fires, building collapse, and traffic accidents from aerial images captured via UAVs and uses onboard GPS for geolocation. All processing is done on-device using a quantized MobileNetV2 model, ensuring edge-only operation without cloud dependency.

---

## üöÄ Key Features

- ‚úÖ Lightweight **MobileNetV2** model optimized for **ESP32-S3**
- ‚úÖ Input image support for **96√ó96√ó3** and **126√ó126√ó3**
- ‚úÖ Real-time **on-device inference (~1.1 FPS)**
- ‚úÖ Uses **AIDER dataset** (5 disaster classes + normal)
- ‚úÖ **Quantization** with TensorFlow Lite for Microcontrollers
- ‚úÖ **Custom focal loss** and **dynamic learning rate scheduling**
- ‚úÖ Integrated **GPS geolocation** + **store-and-forward communication**
- ‚úÖ Compatible with **UAVs and tower installations**

---

## üß† Model Architecture

- MobileNetV2 (Œ±=0.25) as base
- Lightweight custom classifier head:
  - Flatten ‚Üí Dense(256, ReLU) ‚Üí Dropout(0.3) ‚Üí Dense(5, Softmax)
- Loss: **Custom Focal Loss** (Œ±=0.2, Œ≥=1.5)
- Learning Rate: **Custom decaying scheduler**
- Exported as `.tflite` and converted to C array for deployment

---

## üß™ Dataset

- **AIDER Dataset** ‚Äì Aerial images for emergency response
- 5 disaster classes:
  - Fire, Flood, Collapsed Building, Traffic Accident, Normal
- Balanced subset used: 485 images/class (2,425 total)
- Full dataset support and augmentation pipeline included

---

## ‚öôÔ∏è Hardware Setup

| Component       | Model             |
|----------------|------------------|
| Microcontroller | ESP32-S3-CAM     |
| Camera          | Built-in OV2640  |
| GPS Module      | NEO-6M           |
| Storage         | MicroSD via SD_MMC |
| Battery & Charger | Li-ion + TP4056 |
| Comms (optional) | LoRa or Wi-Fi   |

---

## üõ†Ô∏è Tools & Libraries

- **TensorFlow / TensorFlow Lite**
- **TFLite Micro Interpreter**
- **TinyGPS++**
- **Arduino IDE / PlatformIO**
- **Netron** (for model visualization)
- **Matplotlib**, **Seaborn**, **Scikit-learn** (for metrics)

---

## üìä Results

| Metric               | 96√ó96√ó3      | 126√ó126√ó3     |
|----------------------|--------------|----------------|
| Accuracy             | 94%          | 98%            |
| Inference Time       | 850 ms/frame | 850 ms/frame   |
| Power Consumption    | 160mA @ 5V    | 160mA @ 5V      |
| FPS                  | ~1.1         | ~1.1           |

> All results are validated with on-device testing on ESP32-S3.

---

## üì• Resources

All training logs, metrics, models, and deployment code are shared under this repository for academic use and reproducibility.

> For queries or collaboration, contact: **samik.workofficial@gmail.com**

---

## ‚≠ê Acknowledgements

Special thanks to Dr. Jyoti Yadav (NSUT) for mentorship and guidance, and to the creators of the [AIDER Dataset](https://ieee-dataport.org/documents/aider-aerial-image-dataset-emergency-response-applications) for open access data support.

---

## üìú License

This project is licensed under the **MIT License**.

